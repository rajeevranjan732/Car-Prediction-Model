{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import csv\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1627, 7)\n",
      "(1, 7)\n"
     ]
    }
   ],
   "source": [
    "X_orig=np.loadtxt(open(\"train.csv\", \"rb\"), delimiter=\",\", skiprows=1)\n",
    "X_test_orig=X_orig[0:1,:]\n",
    "X_train_orig=X_orig[1:,:]\n",
    "print(X_train_orig.shape)\n",
    "print(X_test_orig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1627, 1)\n",
      "(1, 1)\n"
     ]
    }
   ],
   "source": [
    "Y_orig=np.reshape(X_orig[:,6],(X_orig.shape[0],1)).astype(int)\n",
    "Y_train_orig=np.reshape(X_train_orig[:,6],(X_train_orig.shape[0],1)).astype(int)\n",
    "Y_test_orig=np.reshape(X_test_orig[:,6],(X_test_orig.shape[0],1)).astype(int)\n",
    "print(Y_train_orig.shape)\n",
    "print(Y_test_orig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1627, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train_orig=X_train_orig[:,0:6].astype(int)\n",
    "X_test_orig=X_test_orig[:,0:6].astype(int)\n",
    "print(X_train_orig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1230,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_orig.reshape(X_train_orig.shape[0], -1).T\n",
    "X_test = X_test_orig.reshape(X_test_orig.shape[0], -1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 1627)\n",
      "(6, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot(Y, C):\n",
    "    Z = np.eye(C)\n",
    "    Y=Z[Y.reshape(-1)%C]\n",
    "    Y=Y.T\n",
    "    return Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 1627\n",
      "number of test examples = 1\n",
      "X_train shape: (6, 1627)\n",
      "Y_train shape: (4, 1627)\n",
      "X_test shape: (6, 1)\n",
      "Y_test shape: (4, 1)\n",
      "[1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Y_train=convert_to_one_hot(Y_train_orig-1,4)\n",
    "Y_test=convert_to_one_hot(Y_test_orig-1,4)\n",
    "\n",
    "print(\"number of training examples = \" + str(X_train.shape[1]))\n",
    "print(\"number of test examples = \" + str(X_test.shape[1]))\n",
    "print(\"X_train shape: \" + str(X_train.shape))\n",
    "print(\"Y_train shape: \" + str(Y_train.shape))\n",
    "print(\"X_test shape: \" + str(X_test.shape))\n",
    "print(\"Y_test shape: \" + str(Y_test.shape))\n",
    "print(Y_train[:,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "\n",
    "    X = tf.placeholder(tf.float32, [n_x, None], name=\"X\")\n",
    "    Y = tf.placeholder(tf.float32, [n_y, None], name=\"Y\")\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = Tensor(\"X_1:0\", shape=(6, ?), dtype=float32)\n",
      "Y = Tensor(\"Y_1:0\", shape=(4, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X, Y = create_placeholders(X_train.shape[0], Y_train.shape[0])\n",
    "print(\"X = \" + str(X))\n",
    "print(\"Y = \" + str(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "\n",
    "            \n",
    "    W1 = tf.get_variable(\"W1\", [100, 6], initializer = tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b1 = tf.get_variable(\"b1\", [100, 1], initializer = tf.zeros_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [90, 100], initializer = tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b2 = tf.get_variable(\"b2\", [90, 1], initializer = tf.zeros_initializer())\n",
    "    W3 = tf.get_variable(\"W3\", [30, 90], initializer = tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b3 = tf.get_variable(\"b3\", [30, 1], initializer = tf.zeros_initializer())\n",
    "    W4 = tf.get_variable(\"W4\", [4, 30], initializer = tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b4 = tf.get_variable(\"b4\", [4, 1], initializer = tf.zeros_initializer())\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3,\n",
    "                  \"W4\": W4,\n",
    "                  \"b4\": b4}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = <tf.Variable 'W1:0' shape=(100, 6) dtype=float32_ref>\n",
      "b1 = <tf.Variable 'b1:0' shape=(100, 1) dtype=float32_ref>\n",
      "W2 = <tf.Variable 'W2:0' shape=(90, 100) dtype=float32_ref>\n",
      "b2 = <tf.Variable 'b2:0' shape=(90, 1) dtype=float32_ref>\n",
      "W3 = <tf.Variable 'W3:0' shape=(30, 90) dtype=float32_ref>\n",
      "b3 = <tf.Variable 'b3:0' shape=(30, 1) dtype=float32_ref>\n",
      "W4 = <tf.Variable 'W4:0' shape=(4, 30) dtype=float32_ref>\n",
      "b4 = <tf.Variable 'b4:0' shape=(4, 1) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    parameters = initialize_parameters()\n",
    "    print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "    print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "    print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "    print(\"b2 = \" + str(parameters[\"b2\"]))\n",
    "    print(\"W3 = \" + str(parameters[\"W3\"]))\n",
    "    print(\"b3 = \" + str(parameters[\"b3\"]))\n",
    "    print(\"W4 = \" + str(parameters[\"W4\"]))\n",
    "    print(\"b4 = \" + str(parameters[\"b4\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "  \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    W4 = parameters['W4']\n",
    "    b4 = parameters['b4']\n",
    "    \n",
    "    Z1 = tf.add(tf.matmul(W1, X), b1)                      # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                    # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2, A1), b2)                     # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                    # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3, A2), b3)                     # Z2 = np.dot(W2, a1) + b2\n",
    "    A3 = tf.nn.relu(Z3)                                    # A2 = relu(Z2)\n",
    "    Z4 = tf.add(tf.matmul(W4, A3), b4)                     # Z3 = np.dot(W3,Z2) + b3\n",
    "    \n",
    "    return Z4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z4 = Tensor(\"Add_3:0\", shape=(4, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(6, 4)\n",
    "    parameters = initialize_parameters()\n",
    "    Z4 = forward_propagation(X, parameters)\n",
    "    print(\"Z4 = \" + str(Z4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Z4, Y):\n",
    "    \n",
    "    logits = tf.transpose(Z4)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 32):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "    mini_batch_size - size of the mini-batches, integer\n",
    "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.00003,num_epochs = 5000, minibatch_size = 2, print_cost = True):\n",
    "\n",
    "    tf.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep consistent results\n",
    "    seed = 3                                          # to keep consistent results\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "\n",
    "    parameters = initialize_parameters()\n",
    "\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    \n",
    "    cost = compute_cost(Z3, Y)\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        sess.run(init)\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                     \n",
    "            num_minibatches = int(m / minibatch_size) \n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "               \n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "                \n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "\n",
    "        parameters = sess.run(parameters)\n",
    "        print(\"Parameters have been trained!\")\n",
    "\n",
    "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
    "\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print(\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print(\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        \n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.916667\n",
      "Cost after epoch 100: 0.129638\n",
      "Cost after epoch 200: 0.089883\n",
      "Cost after epoch 300: 0.062193\n",
      "Cost after epoch 400: 0.042488\n",
      "Cost after epoch 500: 0.029404\n",
      "Cost after epoch 600: 0.017725\n",
      "Cost after epoch 700: 0.011437\n",
      "Cost after epoch 800: 0.006837\n",
      "Cost after epoch 900: 0.003319\n",
      "Cost after epoch 1000: 0.001019\n",
      "Cost after epoch 1100: 0.000394\n",
      "Cost after epoch 1200: 0.000461\n",
      "Cost after epoch 1300: 0.000029\n",
      "Cost after epoch 1400: 0.000005\n",
      "Cost after epoch 1500: 0.000001\n",
      "Cost after epoch 1600: 0.000001\n",
      "Cost after epoch 1700: 0.000000\n",
      "Cost after epoch 1800: 0.000000\n",
      "Cost after epoch 1900: 0.000000\n",
      "Cost after epoch 2000: 0.000001\n",
      "Cost after epoch 2100: 0.000000\n",
      "Cost after epoch 2200: 0.000000\n",
      "Cost after epoch 2300: 0.000000\n",
      "Cost after epoch 2400: 0.000000\n",
      "Cost after epoch 2500: 0.000000\n",
      "Cost after epoch 2600: 0.000000\n",
      "Cost after epoch 2700: 0.000000\n",
      "Cost after epoch 2800: 0.000000\n",
      "Cost after epoch 2900: 0.000000\n",
      "Cost after epoch 3000: 0.000000\n",
      "Cost after epoch 3100: 0.000000\n",
      "Cost after epoch 3200: 0.000000\n",
      "Cost after epoch 3300: 0.000001\n",
      "Cost after epoch 3400: 0.000000\n",
      "Cost after epoch 3500: 0.000000\n",
      "Cost after epoch 3600: 0.000000\n",
      "Cost after epoch 3700: 0.000000\n",
      "Cost after epoch 3800: 0.000000\n",
      "Cost after epoch 3900: 0.000000\n",
      "Cost after epoch 4000: 0.000000\n",
      "Cost after epoch 4100: 0.000000\n",
      "Cost after epoch 4200: 0.000000\n",
      "Cost after epoch 4300: 0.000000\n",
      "Cost after epoch 4400: 0.001935\n",
      "Cost after epoch 4500: 0.000000\n",
      "Cost after epoch 4600: 0.000000\n",
      "Cost after epoch 4700: 0.000000\n",
      "Cost after epoch 4800: 0.000000\n",
      "Cost after epoch 4900: 0.000000\n",
      "Parameters have been trained!\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "parameters = model(X_train, Y_train, X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1244,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final=np.loadtxt(open(\"test.csv\", \"rb\"), delimiter=\",\", skiprows=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, parameters):\n",
    "    \n",
    "    W1 = tf.convert_to_tensor(parameters[\"W1\"])\n",
    "    b1 = tf.convert_to_tensor(parameters[\"b1\"])\n",
    "    W2 = tf.convert_to_tensor(parameters[\"W2\"])\n",
    "    b2 = tf.convert_to_tensor(parameters[\"b2\"])\n",
    "    W3 = tf.convert_to_tensor(parameters[\"W3\"])\n",
    "    b3 = tf.convert_to_tensor(parameters[\"b3\"])\n",
    "    W4 = tf.convert_to_tensor(parameters[\"W4\"])\n",
    "    b4 = tf.convert_to_tensor(parameters[\"b4\"])\n",
    "    \n",
    "    params = {\"W1\": W1,\n",
    "              \"b1\": b1,\n",
    "              \"W2\": W2,\n",
    "              \"b2\": b2,\n",
    "              \"W3\": W3,\n",
    "              \"b3\": b3,\n",
    "              \"W4\": W4,\n",
    "              \"b4\": b4}\n",
    "    \n",
    "    x = tf.placeholder(\"float\", [6, 100])\n",
    "    \n",
    "    z4 = forward_propagation(x, params)\n",
    "    p = tf.argmax(z4)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        prediction = sess.run(p, feed_dict = {x: X})\n",
    "        \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1246,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_final=np.reshape(predict(X_final.T,parameters),(X_final.shape[0],1))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def floatToString(inputValue):\n",
    "    inputValue =  ('%.15f' % inputValue).rstrip('0').rstrip('.')\n",
    "    return inputValue;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1248,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"prediction.csv\", Y_final, delimiter=\",\")\n",
    "np.savetxt(\"X_train.csv\",X_train.T,delimiter=\",\")\n",
    "np.savetxt(\"X_test.csv\",X_test.T,delimiter=\",\")\n",
    "np.savetxt(\"Y_train.csv\",Y_train.T,delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
